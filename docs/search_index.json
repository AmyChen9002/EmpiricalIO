[["assignment7.html", "Chapter 17 Assignment 7: Dynamic Decision 17.1 Simulate data 17.2 Estimate parameters", " Chapter 17 Assignment 7: Dynamic Decision 17.1 Simulate data Suppose that there is a firm and it makes decisions for \\(t = 1, \\cdots, \\infty\\). We solve the model under the infinite-horizon assumption, but generate data only for \\(t = 1, \\cdots, T\\). There are \\(L = 5\\) state \\(s \\in \\{1, 2, 3, 4, 5\\}\\) states for the player. The firm can choose \\(K + 1 = 2\\) actions \\(a \\in \\{0, 1\\}\\). The mean period payoff to the firm is: \\[ \\pi(a, s) := \\alpha \\ln s - \\beta a, \\] where \\(\\alpha, \\beta &gt; 0\\). The period payoff is: \\[ \\pi(a, s) + \\epsilon(a), \\] and \\(\\epsilon(a)\\) is an i.i.d. type-I extreme random variable that is independent of all the other variables. At the beginning of each period, the state \\(s\\) and choice-specific shocks \\(\\epsilon(a), a = 0, 1\\) are realized, and the the firm chooses her action. Then, the game moves to the next period. Suppose that \\(s &gt; 1\\) and \\(s &lt; L\\). If \\(a = 0\\), the state stays at the same state with probability \\(1 - \\kappa\\) and moves down by 1 with probability \\(\\kappa\\). If \\(a = 1\\), the state moves up by 1 with probability \\(\\gamma\\), moves down by 1 with probability \\(\\kappa\\), and stays at the same with probability \\(1 - \\kappa - \\gamma\\). Suppose that \\(s = 1\\). If \\(a = 0\\), the state stays at the same state with probability 1. If \\(a = 1\\), the state moves up by 1 with probability \\(\\gamma\\) and stays at the same with probability \\(1 - \\gamma\\). Suppose that \\(s = L\\). If \\(a = 0\\), the state stays at the same state with probability \\(1 - \\kappa\\) and moves down by 1 with probability \\(\\kappa\\). If \\(a = 1\\), the state moves down by 1 with probability \\(\\kappa\\), and stays at the same with probability \\(1 - \\kappa\\). The mean period profit is summarized in \\(\\Pi\\) as: \\[ \\Pi := \\begin{pmatrix} \\pi(0, 1)\\\\ \\vdots\\\\ \\pi(K, 1)\\\\ \\vdots \\\\ \\pi(0, L)\\\\ \\vdots\\\\ \\pi(K, L)\\\\ \\end{pmatrix} \\] The transition law is summarized in \\(G\\) as: \\[ g(a, s, s&#39;) := \\mathbb{P}\\{s_{t + 1} = s&#39;|s_t = s, a_t = a\\}, \\] \\[ G := \\begin{pmatrix} g(0, 1, 1) &amp; \\cdots &amp; g(0, 1, L)\\\\ \\vdots &amp; &amp; \\vdots \\\\ g(K, 1, 1) &amp; \\cdots &amp; g(K, 1, L)\\\\ &amp; \\vdots &amp; \\\\ g(0, L, 1) &amp; \\cdots &amp; g(0, L, L)\\\\ \\vdots &amp; &amp; \\vdots \\\\ g(K, L, 1) &amp; \\cdots &amp; g(K, L, L)\\\\ \\end{pmatrix}. \\] The discount factor is denoted by \\(\\delta\\). We simulate data for \\(N\\) firms for \\(T\\) periods each. Set constants and parameters as follows: # set seed set.seed(1) # set constants L &lt;- 5 K &lt;- 1 T &lt;- 100 N &lt;- 1000 lambda &lt;- 1e-10 # set parameters alpha &lt;- 0.5 beta &lt;- 3 kappa &lt;- 0.1 gamma &lt;- 0.6 delta &lt;- 0.95 Write function compute_pi(alpha, beta, L, K) that computes \\(\\Pi\\) given parameters and compute the true \\(\\Pi\\) under the true parameters. Don’t use methods in dplyr and deal with matrix operations. PI &lt;- compute_PI( alpha = alpha, beta = beta, L = L, K = K ); PI ## [,1] ## k0_l1 0.0000000 ## k1_l1 -3.0000000 ## k0_l2 0.3465736 ## k1_l2 -2.6534264 ## k0_l3 0.5493061 ## k1_l3 -2.4506939 ## k0_l4 0.6931472 ## k1_l4 -2.3068528 ## k0_l5 0.8047190 ## k1_l5 -2.1952810 Write function compute_G(kappa, gamma, L, K) that computes \\(G\\) given parameters and compute the true \\(G\\) under the true parameters. Don’t use methods in dplyr and deal with matrix operations. G &lt;- compute_G( kappa = kappa, gamma = gamma, L = L, K = K ); G ## l1 l2 l3 l4 l5 ## k0_l1 1.0 0.0 0.0 0.0 0.0 ## k1_l1 0.4 0.6 0.0 0.0 0.0 ## k0_l2 0.1 0.9 0.0 0.0 0.0 ## k1_l2 0.1 0.3 0.6 0.0 0.0 ## k0_l3 0.0 0.1 0.9 0.0 0.0 ## k1_l3 0.0 0.1 0.3 0.6 0.0 ## k0_l4 0.0 0.0 0.1 0.9 0.0 ## k1_l4 0.0 0.0 0.1 0.3 0.6 ## k0_l5 0.0 0.0 0.0 0.1 0.9 ## k1_l5 0.0 0.0 0.0 0.1 0.9 The exante-value function is written as a function of a conditional choice probability as follows: \\[ \\varphi^{(\\theta_1, \\theta_2)}(p) := [I - \\delta \\Sigma(p) G]^{-1}\\Sigma(p)[\\Pi + E(p)], \\] where \\(\\theta_1 = (\\alpha, \\beta)\\) and \\(\\theta_2 = (\\kappa, \\gamma)\\) and: \\[ \\Sigma(p) = \\begin{pmatrix} p(1)&#39; &amp; &amp; \\\\ &amp; \\ddots &amp; \\\\ &amp; &amp; p(L)&#39; \\end{pmatrix} \\] and: \\[ E(p) = \\gamma - \\ln p. \\] Write a function compute_exante_value(p, PI, G, L, K, delta) that returns the exante value function given a conditional choice probability. Don’t use methods in dplyr and deal with matrix operations. When a choice probability is zero at some element, the corresponding element of \\(E(p)\\) can be set at zero, because anyway we multiply the zero probability to the element and the corresponding element in \\(E(p)\\) does not affect the result. p &lt;- matrix( rep(0.5, L * (K + 1)), ncol = 1 ); p ## [,1] ## [1,] 0.5 ## [2,] 0.5 ## [3,] 0.5 ## [4,] 0.5 ## [5,] 0.5 ## [6,] 0.5 ## [7,] 0.5 ## [8,] 0.5 ## [9,] 0.5 ## [10,] 0.5 V &lt;- compute_exante_value( p = p, PI = PI, G = G, L = L, K = K, delta = delta ); V ## [,1] ## l1 5.777876 ## l2 7.597282 ## l3 9.126304 ## l4 10.115439 ## l5 10.593438 The optimal conditional choice probability is written as a function of an exante value function as follows: \\[ \\Lambda^{(\\theta_1, \\theta_2)}(V)(a, s) := \\frac{\\exp[\\pi(a, s) + \\delta \\sum_{s&#39;}V(s&#39;)g(a, s, s&#39;)]}{\\sum_{a&#39;}\\exp[\\pi(a&#39;, s) + \\delta \\sum_{s&#39;}V(s&#39;)g(a&#39;, s, s&#39;)]}, \\] where \\(V\\) is an exante value function. Write a function compute_ccp(V, PI, G, L, K, delta) that returns the optimal conditional choice probability given an exante value function. Don’t use methods in dplyr and deal with matrix operations. To do so, write a function compute_choice_value(V, PI, G, delta) that returns the choice-specific value function. Use this for debugging by checking if the results are intuitive. value &lt;- compute_choice_value( V = V, PI = PI, G = G, delta = delta ); value ## [,1] ## k0_l1 5.488982 ## k1_l1 3.526044 ## k0_l2 7.391148 ## k1_l2 5.262691 ## k0_l3 9.074038 ## k1_l3 6.637845 ## k0_l4 10.208846 ## k1_l4 7.481306 ## k0_l5 10.823075 ## k1_l5 7.823075 p &lt;- compute_ccp( V = V, PI = PI, G = G, L = L, K = K, delta = delta ); p ## [,1] ## k0_l1 0.87685057 ## k1_l1 0.12314943 ## k0_l2 0.89363847 ## k1_l2 0.10636153 ## k0_l3 0.91954591 ## k1_l3 0.08045409 ## k0_l4 0.93863232 ## k1_l4 0.06136768 ## k0_l5 0.95257413 ## k1_l5 0.04742587 Write a function that find the equilibrium conditional choice probability and ex-ante value function by iterating the update of an exante value function and an optimal conditional choice probability. The iteration should stop when \\(\\max_s|V^{(r + 1)}(s) - V^{(r)}(s)| &lt; \\lambda\\) with \\(\\lambda = 10^{-10}\\). output &lt;- solve_dynamic_decision( PI = PI, G = G, L = L, K = K, delta = delta, lambda = lambda ); output ## $p ## [,1] ## k0_l1 0.82218962 ## k1_l1 0.17781038 ## k0_l2 0.80024354 ## k1_l2 0.19975646 ## k0_l3 0.83074516 ## k1_l3 0.16925484 ## k0_l4 0.87691534 ## k1_l4 0.12308466 ## k0_l5 0.95257413 ## k1_l5 0.04742587 ## ## $V ## [,1] ## l1 15.46000 ## l2 18.03675 ## l3 20.86514 ## l4 23.33721 ## l5 25.15557 p &lt;- output$p V &lt;- output$V value &lt;- compute_choice_value( V = V, PI = PI, G = G, delta = delta ); value ## [,1] ## k0_l1 14.68700 ## k1_l1 13.15574 ## k0_l2 17.23669 ## k1_l2 15.84887 ## k0_l3 20.10249 ## k1_l3 18.51157 ## k0_l4 22.62865 ## k1_l4 20.66511 ## k0_l5 24.52976 ## k1_l5 21.52976 Write a function simulate_dynamic_decision(p, s, PI, G, L, K, T, delta, seed) that simulate the data for a single firm starting from an initial state for \\(T\\) periods. The function should accept a value of seed and set the seed at the beginning of the procedure inside the function, because the process is stochastic. # set initial value s &lt;- 1 # draw simulation for a firm seed &lt;- 1 df &lt;- simulate_dynamic_decision( p = p, s = s, G = G, L = L, K = K, T = T, delta = delta, seed = seed ); df ## # A tibble: 100 × 3 ## t s a ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0 ## 2 2 1 0 ## 3 3 1 0 ## 4 4 1 1 ## 5 5 2 1 ## 6 6 1 0 ## 7 7 1 0 ## 8 8 1 0 ## 9 9 1 0 ## 10 10 1 0 ## # … with 90 more rows Write a function simulate_dynamic_decision_across_firms(p, s, PI, G, L, K, T, N, delta) that returns simulation data for \\(N\\) firm. For firm \\(i\\), set the seed at \\(i\\) df &lt;- simulate_dynamic_decision_across_firms( p = p, s = s, G = G, L = L, K = K, T = T, N = N, delta = delta ) saveRDS( df, file = &quot;data/a7/A7_df.rds&quot; ) df &lt;- readRDS(file = &quot;data/a7/A7_df.rds&quot;) df ## # A tibble: 100,000 × 4 ## i t s a ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 1 0 ## 2 1 2 1 0 ## 3 1 3 1 0 ## 4 1 4 1 1 ## 5 1 5 2 1 ## 6 1 6 1 0 ## 7 1 7 1 0 ## 8 1 8 1 0 ## 9 1 9 1 0 ## 10 1 10 1 0 ## # … with 99,990 more rows Write a function estimate_ccp(df) that returns a non-parametric estimate of the conditional choice probability in the data. Compare the estimated conditional choice probability and the true conditional choice probability by a bar plot. p_est &lt;- estimate_ccp(df = df) check_ccp &lt;- cbind( p, p_est ) colnames(check_ccp) &lt;- c( &quot;true&quot;, &quot;estimate&quot; ) check_ccp &lt;- check_ccp %&gt;% reshape2::melt() ggplot( data = check_ccp, aes( x = Var1, y = value, fill = Var2 ) ) + geom_bar( stat = &quot;identity&quot;, position = &quot;dodge&quot; ) + labs(fill = &quot;Value&quot;) + xlab(&quot;action/state&quot;) + ylab(&quot;probability&quot;) Write a function estimate_G(df) that returns a non-parametric estiamte of the transition matrix in the data. Compare the estimated transition matrix and the true transition matrix by a bar plot. G_est &lt;- estimate_G(df = df); G_est ## l1 l2 l3 l4 l5 ## k0_l1 1.0000000 0.00000000 0.0000000 0.00000000 0.0000000 ## k1_l1 0.3930818 0.60691824 0.0000000 0.00000000 0.0000000 ## k0_l2 0.1012162 0.89878384 0.0000000 0.00000000 0.0000000 ## k1_l2 0.1031410 0.31276454 0.5840945 0.00000000 0.0000000 ## k0_l3 0.0000000 0.09660837 0.9033916 0.00000000 0.0000000 ## k1_l3 0.0000000 0.09974569 0.3071489 0.59310540 0.0000000 ## k0_l4 0.0000000 0.00000000 0.1012564 0.89874358 0.0000000 ## k1_l4 0.0000000 0.00000000 0.1039339 0.29966003 0.5964060 ## k0_l5 0.0000000 0.00000000 0.0000000 0.09891400 0.9010860 ## k1_l5 0.0000000 0.00000000 0.0000000 0.09751037 0.9024896 check_G &lt;- data.frame( type = &quot;true&quot;, reshape2::melt(G) ) check_G_est &lt;- data.frame( type = &quot;estimate&quot;, reshape2::melt(G_est) ) check_G &lt;- rbind( check_G, check_G_est ) check_G$variable &lt;- paste( check_G$Var1, check_G$Var2, sep = &quot;_&quot; ) ggplot( data = check_G, aes( x = variable, y = value, fill = type ) ) + geom_bar( stat = &quot;identity&quot;, position = &quot;dodge&quot; ) + labs(fill = &quot;Value&quot;) + xlab(&quot;action/state/state&quot;) + ylab(&quot;probability&quot;) + theme(axis.text.x = element_blank()) 17.2 Estimate parameters Vectorize the parameters as follows: theta_1 &lt;- c( alpha, beta ) theta_2 &lt;- c( kappa, gamma ) theta &lt;- c( theta_1, theta_2 ) First, we estimate the parameters by a nested fixed-point algorithm. The loglikelihood for \\(\\{a_{it}, s_{it}\\}_{i = 1, \\cdots, N, t = 1, \\cdots, T}\\) is: \\[ \\frac{1}{NT} \\sum_{i = 1}^N \\sum_{t = 1}^T[\\log\\mathbb{P}\\{a_{it}|s_{it}\\} + \\log \\mathbb{P}\\{s_{i, t + 1}|a_{it}, s_{it}\\}], \\] with \\(\\mathbb{P}\\{s_{i, T + 1}|a_{iT}, s_{iT}\\} = 1\\) for all \\(i\\) as \\(s_{i, T + 1}\\) is not observed. Write a function compute_loglikelihood_NFP(theta, df, delta, L, K) that compute the loglikelihood. loglikelihood &lt;- compute_loglikelihood_NFP( theta = theta, df = df, delta = delta, L = L, K = K ); loglikelihood ## [1] -0.7474961 Check the value of the objective function around the true parameter. # label label &lt;- c( &quot;\\\\alpha&quot;, &quot;\\\\beta&quot;, &quot;\\\\kappa&quot;, &quot;\\\\gamma&quot; ) label &lt;- paste( &quot;$&quot;, label, &quot;$&quot;, sep = &quot;&quot; ) # compute the graph graph &lt;- foreach ( i = 1:length(theta) ) %do% { theta_i &lt;- theta[i] theta_i_list &lt;- theta_i * seq( 0.8, 1.2, by = 0.05 ) objective_i &lt;- foreach ( j = 1:length(theta_i_list), .combine = &quot;rbind&quot; ) %do% { theta_ij &lt;- theta_i_list[j] theta_j &lt;- theta theta_j[i] &lt;- theta_ij objective_ij &lt;- compute_loglikelihood_NFP( theta_j, df, delta, L, K ); loglikelihood return(objective_ij) } df_graph &lt;- data.frame( x = theta_i_list, y = objective_i ) g &lt;- ggplot( data = df_graph, aes( x = x, y = y ) ) + geom_point() + geom_vline( xintercept = theta_i, linetype = &quot;dotted&quot; ) + ylab(&quot;objective function&quot;) + xlab(TeX(label[i])) return(g) } saveRDS( graph, file = &quot;data/a7/A7_NFP_graph.rds&quot; ) graph &lt;- readRDS(file = &quot;data/a7/A7_NFP_graph.rds&quot;) graph ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] Estiamte the parameters by maximizing the loglikelihood. To keep the model to be well-defined, impose an ad hoc lower and upper bounds such that \\(\\alpha \\in [0, 1], \\beta \\in [0, 5], \\kappa \\in [0, 0.2], \\gamma \\in [0, 0.7]\\). lower &lt;- rep(0, length(theta)) upper &lt;- c(1, 5, 0.2, 0.7) NFP_result &lt;- optim( par = theta, fn = compute_loglikelihood_NFP, method = &quot;L-BFGS-B&quot;, lower = lower, upper = upper, control = list(fnscale = -1), df = df, delta = delta, L = L, K = K ) saveRDS( NFP_result, file = &quot;data/a7/A7_NFP_result.rds&quot; ) NFP_result &lt;- readRDS(file = &quot;data/a7/A7_NFP_result.rds&quot;) NFP_result ## $par ## [1] 0.5273235 3.0652558 0.1000122 0.5955431 ## ## $value ## [1] -0.7474743 ## ## $counts ## function gradient ## 21 21 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; compare &lt;- data.frame( true = theta, estimate = NFP_result$par ); compare ## true estimate ## 1 0.5 0.5273235 ## 2 3.0 3.0652558 ## 3 0.1 0.1000122 ## 4 0.6 0.5955431 Next, we estimate the parameters by CCP approach. Write a function estimate_theta_2(df) that returns the estimates of \\(\\kappa\\) and \\(\\gamma\\) directly from data by counting relevant events. theta_2_est &lt;- estimate_theta_2(df = df); theta_2_est ## [1] 0.09988488 0.59551895 The objective function of the minimum distance estimator based on the conditional choice probability approach is: \\[ \\frac{1}{KL}\\sum_{s = 1}^L \\sum_{a = 1}^K\\{\\hat{p}(a, s) - p^{(\\theta_1, \\theta_2)}(a, s)\\}^2, \\] where \\(\\hat{p}\\) is the non-parametric estimate of the conditional choice probability and \\(p^{(\\theta_1, \\theta_2)}\\) is the optimal conditional choice probability under parameters \\(\\theta_1\\) and \\(\\theta_2\\). Write a function compute_CCP_objective(theta_1, theta_2, p_est, L, K, delta) that returns the objective function of the above minimum distance estimator given a non-parametric estimate of the conditional choice probability and \\(\\theta_1\\) and \\(\\theta_2\\). compute_CCP_objective( theta_1 = theta_1, theta_2 = theta_2, p_est = p_est, L = L, K = K, delta = delta ) ## [1] 5.000511e-06 Check the value of the objective function around the true parameter. # label label &lt;- c( &quot;\\\\alpha&quot;, &quot;\\\\beta&quot; ) label &lt;- paste( &quot;$&quot;, label, &quot;$&quot;, sep = &quot;&quot; ) # compute the graph graph &lt;- foreach ( i = 1:length(theta_1) ) %do% { theta_i &lt;- theta_1[i] theta_i_list &lt;- theta_i * seq( 0.8, 1.2, by = 0.05 ) objective_i &lt;- foreach ( j = 1:length(theta_i_list), .combine = &quot;rbind&quot; ) %do% { theta_ij &lt;- theta_i_list[j] theta_j &lt;- theta_1 theta_j[i] &lt;- theta_ij objective_ij &lt;- compute_CCP_objective( theta_j, theta_2, p_est, L, K, delta ) return(objective_ij) } df_graph &lt;- data.frame( x = theta_i_list, y = objective_i ) g &lt;- ggplot( data = df_graph, aes( x = x, y = y) ) + geom_point() + geom_vline( xintercept = theta_i, linetype = &quot;dotted&quot; ) + ylab(&quot;objective function&quot;) + xlab(TeX(label[i])) return(g) } saveRDS( graph, file = &quot;data/a7/A7_CCP_graph.rds&quot; ) graph &lt;- readRDS(file = &quot;data/a7/A7_CCP_graph.rds&quot;) graph ## [[1]] ## ## [[2]] Estiamte the parameters by minimizing the objective function. To keep the model to be well-defined, impose an ad hoc lower and upper bounds such that \\(\\alpha \\in [0, 1], \\beta \\in [0, 5]\\). lower &lt;- rep(0, length(theta_1)) upper &lt;- c(1, 5) CCP_result &lt;- optim( par = theta_1, fn = compute_CCP_objective, method = &quot;L-BFGS-B&quot;, lower = lower, upper = upper, theta_2 = theta_2_est, p_est = p_est, L = L, K = K, delta = delta ) saveRDS( CCP_result, file = &quot;data/a7/A7_CCP_result.rds&quot; ) CCP_result &lt;- readRDS(file = &quot;data/a7/A7_CCP_result.rds&quot;) CCP_result ## $par ## [1] 0.5271684 3.0644600 ## ## $value ## [1] 1.790528e-06 ## ## $counts ## function gradient ## 11 11 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; compare &lt;- data.frame( true = theta_1, estimate = CCP_result$par ); compare ## true estimate ## 1 0.5 0.5271684 ## 2 3.0 3.0644600 "]]
